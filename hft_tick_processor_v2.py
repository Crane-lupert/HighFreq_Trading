"""
HFT ì „ëµì„ ìœ„í•œ ê³ ì„±ëŠ¥ ì½”ìŠ¤ì½¤ í‹±ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ v2
- íŠ¹ì • ê¸°ê°„ ì„ íƒ ì „ì²˜ë¦¬ ì¶”ê°€
- ë©€í‹°íŒŒì¼ ì¿¼ë¦¬ ëª…í™•í™”
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
"""

import gzip
import os
import re
from pathlib import Path
from typing import List, Optional, Dict, Tuple
from datetime import datetime
import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq
from tqdm import tqdm


class TickDataConverter:
    """í‹±ë°ì´í„°ë¥¼ Parquetë¡œ ë³€í™˜ (ì „ì²˜ë¦¬ìš©)"""
    
    # ì£¼ì‹ìš© í•„ìˆ˜ ì»¬ëŸ¼ (HFTì— í•„ìš”í•œ ê²ƒë§Œ)
    STOCK_ESSENTIAL_COLS = {
        'TRADE_DATE': 0,
        'ISIN_CODE': 3,
        'TRD_PRC': 6,
        'TRDVOL': 7,
        'TRD_TM': 10,
        'OPEN_PRICE': 35,
        'HIGH_PRICE': 36,
        'LOW_PRICE': 37,
        'ACC_TRDVOL': 39,
        'ACC_AMT': 40,
        'LST_ASKBID_TP_CD': 41,
    }
    
    # íŒŒìƒìƒí’ˆìš© í•„ìˆ˜ ì»¬ëŸ¼
    DERIVATIVE_ESSENTIAL_COLS = {
        'TRADE_DATE': 0,
        'ISIN_CODE': 2,
        'JONG_INDEX': 3,
        'TRD_PRC': 4,
        'TRDVOL': 5,
        'TRD_TM': 8,
        'OPEN_PRICE': 11,
        'HIGH_PRICE': 12,
        'LOW_PRICE': 13,
        'ACC_TRDVOL': 15,
        'ACC_AMT': 16,
        'LST_ASKBID_TP_CD': 17,
    }
    
    @staticmethod
    def parse_filename_period(filename: str) -> Optional[Tuple[int, int]]:
        """
        íŒŒì¼ëª…ì—ì„œ ì—°ë„ì™€ ë¶„ê¸°/ì›” ì¶”ì¶œ
        
        Returns:
            (year, quarter_or_month) ë˜ëŠ” None
        
        Examples:
            'DFKNXTRDSHRTH_2017_Q1.dat.gz' -> (2017, 1)
            'SKSNXTRDIJH_2010_02.dat.txt.gz' -> (2010, 2)
        """
        # íŒ¨í„´ 1: YYYY_QN (ë¶„ê¸°)
        match = re.search(r'(\d{4})_Q(\d)', filename)
        if match:
            return int(match.group(1)), int(match.group(2))
        
        # íŒ¨í„´ 2: YYYY_MM (ì›”)
        match = re.search(r'(\d{4})_(\d{2})', filename)
        if match:
            return int(match.group(1)), int(match.group(2))
        
        return None
    
    @staticmethod
    def filter_files_by_period(
        file_paths: List[Path],
        start_year: Optional[int] = None,
        end_year: Optional[int] = None,
        quarters: Optional[List[int]] = None,
        months: Optional[List[int]] = None
    ) -> List[Path]:
        """
        íŒŒì¼ëª… ê¸°ë°˜ìœ¼ë¡œ ê¸°ê°„ í•„í„°ë§
        
        Args:
            file_paths: íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            start_year: ì‹œì‘ ì—°ë„ (í¬í•¨)
            end_year: ì¢…ë£Œ ì—°ë„ (í¬í•¨)
            quarters: ë¶„ê¸° ë¦¬ìŠ¤íŠ¸ [1,2,3,4]
            months: ì›” ë¦¬ìŠ¤íŠ¸ [1,2,...,12]
        
        Returns:
            í•„í„°ë§ëœ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
        
        Examples:
            # 2017~2019ë…„ 1ë¶„ê¸°ë§Œ
            filter_files_by_period(files, start_year=2017, end_year=2019, quarters=[1])
            
            # 2020ë…„ 1~3ì›”ë§Œ
            filter_files_by_period(files, start_year=2020, end_year=2020, months=[1,2,3])
        """
        filtered = []
        
        for file_path in file_paths:
            period = TickDataConverter.parse_filename_period(file_path.name)
            if period is None:
                continue
            
            year, period_num = period
            
            # ì—°ë„ í•„í„°
            if start_year and year < start_year:
                continue
            if end_year and year > end_year:
                continue
            
            # ë¶„ê¸°/ì›” í•„í„°
            if quarters and period_num in quarters:
                filtered.append(file_path)
            elif months and period_num in months:
                filtered.append(file_path)
            elif quarters is None and months is None:
                # í•„í„° ì—†ìœ¼ë©´ ì—°ë„ë§Œ ì²´í¬
                filtered.append(file_path)
        
        return filtered
    
    @staticmethod
    def convert_to_parquet(
        gz_path: str,
        output_dir: str,
        is_derivative: bool = False,
        chunk_size: int = 1000000
    ):
        """
        GZ íŒŒì¼ì„ Parquetë¡œ ë³€í™˜ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
        
        Args:
            gz_path: ì…ë ¥ .dat.gz íŒŒì¼
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            is_derivative: Trueë©´ ì„ ë¬¼/ì˜µì…˜, Falseë©´ ì£¼ì‹
            chunk_size: ì²­í¬ í¬ê¸° (ê¸°ë³¸ 100ë§Œ í–‰)
        """
        filename = Path(gz_path).stem.replace('.dat', '').replace('.txt', '')
        output_path = Path(output_dir) / f"{filename}.parquet"
        
        # ì´ë¯¸ ë³€í™˜ëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ìŠ¤í‚µ
        if output_path.exists():
            print(f"â­ï¸  ìŠ¤í‚µ (ì´ë¯¸ ì¡´ì¬): {filename}")
            return
        
        # í•„ìˆ˜ ì»¬ëŸ¼ ì„ íƒ
        cols = (TickDataConverter.DERIVATIVE_ESSENTIAL_COLS 
                if is_derivative 
                else TickDataConverter.STOCK_ESSENTIAL_COLS)
        
        print(f"ë³€í™˜ ì¤‘: {Path(gz_path).name}")
        
        chunk_data = []
        chunk_count = 0
        writer = None
        schema = None
        
        with gzip.open(gz_path, 'rb') as f:
            for line_no, line in enumerate(tqdm(f, desc="ì½ëŠ” ì¤‘")):
                try:
                    decoded = line.decode('euc-kr').strip()
                except:
                    decoded = line.decode('cp949').strip()
                
                fields = decoded.split('|')
                
                # í•„ìˆ˜ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
                row = {name: fields[idx] if idx < len(fields) else None 
                       for name, idx in cols.items()}
                chunk_data.append(row)
                
                # ì²­í¬ ë‹¨ìœ„ë¡œ ì €ì¥
                if len(chunk_data) >= chunk_size:
                    df_chunk = pd.DataFrame(chunk_data)
                    df_chunk = TickDataConverter._convert_dtypes(df_chunk, is_derivative)
                    table = pa.Table.from_pandas(df_chunk)
                    
                    if writer is None:
                        schema = table.schema
                        writer = pq.ParquetWriter(output_path, schema, compression='snappy')
                    
                    writer.write_table(table)
                    chunk_data = []
                    chunk_count += 1
        
        # ë§ˆì§€ë§‰ ì²­í¬ ì €ì¥
        if chunk_data:
            df_chunk = pd.DataFrame(chunk_data)
            df_chunk = TickDataConverter._convert_dtypes(df_chunk, is_derivative)
            table = pa.Table.from_pandas(df_chunk)
            
            if writer is None:
                writer = pq.ParquetWriter(output_path, table.schema, compression='snappy')
            
            writer.write_table(table)
        
        if writer:
            writer.close()
        
        # íŒŒì¼ í¬ê¸° ë¹„êµ
        orig_size = os.path.getsize(gz_path) / (1024**3)
        new_size = os.path.getsize(output_path) / (1024**3)
        compression_ratio = (1 - new_size/orig_size) * 100
        
        print(f"âœ“ ì™„ë£Œ: {filename}")
        print(f"  ì›ë³¸: {orig_size:.2f} GB â†’ ë³€í™˜: {new_size:.2f} GB (ì••ì¶•ë¥ : {compression_ratio:.1f}%)\n")
    
    @staticmethod
    def _convert_dtypes(df: pd.DataFrame, is_derivative: bool) -> pd.DataFrame:
        """ë°ì´í„° íƒ€ì… ìµœì í™”"""
        numeric_cols = ['TRD_PRC', 'TRDVOL', 'OPEN_PRICE', 'HIGH_PRICE', 
                       'LOW_PRICE', 'ACC_TRDVOL', 'ACC_AMT']
        
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        if 'TRDVOL' in df.columns:
            df['TRDVOL'] = df['TRDVOL'].astype('int32')
        if 'ACC_TRDVOL' in df.columns:
            df['ACC_TRDVOL'] = df['ACC_TRDVOL'].astype('int64')
        if 'ACC_AMT' in df.columns:
            df['ACC_AMT'] = df['ACC_AMT'].astype('int64')
        
        if 'LST_ASKBID_TP_CD' in df.columns:
            df['LST_ASKBID_TP_CD'] = df['LST_ASKBID_TP_CD'].astype('category')
        
        if is_derivative and 'ISIN_CODE' in df.columns:
            df['ISIN_CODE'] = df['ISIN_CODE'].astype('category')
        
        return df
    
    @staticmethod
    def batch_convert(
        input_dir: str,
        output_dir: str,
        pattern: str = "*.dat.gz",
        is_derivative: bool = False,
        # ğŸ†• ê¸°ê°„ í•„í„° ì˜µì…˜
        start_year: Optional[int] = None,
        end_year: Optional[int] = None,
        quarters: Optional[List[int]] = None,
        months: Optional[List[int]] = None
    ):
        """
        ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼ ì¼ê´„ ë³€í™˜ (ê¸°ê°„ í•„í„° ê°€ëŠ¥)
        
        Examples:
            # ì „ì²´ ë³€í™˜
            batch_convert(input_dir, output_dir, is_derivative=True)
            
            # 2017~2019ë…„ë§Œ
            batch_convert(input_dir, output_dir, is_derivative=True,
                         start_year=2017, end_year=2019)
            
            # 2020ë…„ 1ë¶„ê¸°ë§Œ
            batch_convert(input_dir, output_dir, is_derivative=True,
                         start_year=2020, end_year=2020, quarters=[1])
        """
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        # íŒŒì¼ ê²€ìƒ‰
        all_files = list(Path(input_dir).glob(pattern))
        
        # ğŸ†• ê¸°ê°„ í•„í„° ì ìš©
        if start_year or end_year or quarters or months:
            filtered_files = TickDataConverter.filter_files_by_period(
                all_files, start_year, end_year, quarters, months
            )
            print(f"ê¸°ê°„ í•„í„° ì ìš©: {len(all_files)}ê°œ â†’ {len(filtered_files)}ê°œ")
        else:
            filtered_files = all_files
        
        if not filtered_files:
            print("ë³€í™˜í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ì´ {len(filtered_files)}ê°œ íŒŒì¼ ë³€í™˜ ì‹œì‘\n")
        print("="*80)
        
        for i, file_path in enumerate(filtered_files, 1):
            print(f"\n[{i}/{len(filtered_files)}] {file_path.name}")
            try:
                TickDataConverter.convert_to_parquet(
                    str(file_path),
                    output_dir,
                    is_derivative
                )
            except Exception as e:
                print(f"âœ— ì˜¤ë¥˜: {e}")
                continue


class MultiFileTickLoader:
    """
    ğŸ†• ì—¬ëŸ¬ Parquet íŒŒì¼ì„ ë™ì‹œì— ì¿¼ë¦¬
    - íŒŒì¼ë³„ë¡œ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ì§€ ì•Šê³  í•„í„°ë§
    - í•„ìš”í•œ ë°ì´í„°ë§Œ ìµœì¢…ì ìœ¼ë¡œ ë©”ëª¨ë¦¬ ë¡œë“œ
    """
    
    @staticmethod
    def load_period_polars(
        parquet_dir: str,
        start_year: int,
        end_year: int,
        filters: Optional[Dict] = None,
        columns: Optional[List[str]] = None
    ):
        """
        íŠ¹ì • ê¸°ê°„ì˜ ì—¬ëŸ¬ Parquet íŒŒì¼ì„ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ë¡œë“œ
        
        âš ï¸ ì£¼ì˜: ë©”ëª¨ë¦¬ì— ì‹¤ì œë¡œ ì˜¬ë¼ê°€ëŠ” ì‹œì ì€ .collect() í˜¸ì¶œ ì‹œ!
        
        Args:
            parquet_dir: Parquet íŒŒì¼ ë””ë ‰í† ë¦¬
            start_year: ì‹œì‘ ì—°ë„
            end_year: ì¢…ë£Œ ì—°ë„
            filters: ì¶”ê°€ í•„í„° ì¡°ê±´
            columns: ì½ì„ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            polars.DataFrame (ë©”ëª¨ë¦¬ì— ë¡œë“œë¨)
        
        Example:
            # 2017~2019ë…„ KOSPI200 ì„ ë¬¼ ë°ì´í„°
            df = load_period_polars(
                'E:/parquet/futures',
                2017, 2019,
                filters={'ISIN_CODE': 'KR4101M30004'},
                columns=['TRD_TM', 'TRD_PRC', 'TRDVOL']
            )
        """
        import polars as pl
        
        # íŒŒì¼ ê²€ìƒ‰
        all_files = list(Path(parquet_dir).glob("*.parquet"))
        
        # ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” íŒŒì¼ë§Œ í•„í„°ë§
        period_files = []
        for file in all_files:
            period = TickDataConverter.parse_filename_period(file.name)
            if period:
                year, _ = period
                if start_year <= year <= end_year:
                    period_files.append(file)
        
        if not period_files:
            raise ValueError(f"{start_year}~{end_year}ë…„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"ë¡œë”©í•  íŒŒì¼: {len(period_files)}ê°œ")
        for f in period_files:
            print(f"  - {f.name}")
        
        # ğŸ”‘ í•µì‹¬: ì—¬ëŸ¬ íŒŒì¼ì„ í•˜ë‚˜ì˜ LazyFrameìœ¼ë¡œ ìŠ¤ìº”
        # ì´ ì‹œì ì—ëŠ” ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê±°ì˜ 0!
        df = pl.scan_parquet([str(f) for f in period_files])
        
        # í•„í„° ì ìš© (ì•„ì§ ë©”ëª¨ë¦¬ ì•ˆ ì”€)
        if filters:
            for col, value in filters.items():
                if isinstance(value, list):
                    df = df.filter(pl.col(col).is_in(value))
                else:
                    df = df.filter(pl.col(col) == value)
        
        # ì»¬ëŸ¼ ì„ íƒ (ì•„ì§ ë©”ëª¨ë¦¬ ì•ˆ ì”€)
        if columns:
            df = df.select(columns)
        
        # ì‹¤í–‰! (ì—¬ê¸°ì„œ ë©”ëª¨ë¦¬ì— ë¡œë“œë¨)
        print(f"\në°ì´í„° ë¡œë”© ì¤‘...")
        result = df.collect()
        
        print(f"âœ“ ì™„ë£Œ: {len(result):,}ê°œ í–‰ ë¡œë“œë¨")
        return result
    
    @staticmethod
    def query_period_duckdb(
        parquet_dir: str,
        start_year: int,
        end_year: int,
        sql_query: str
    ):
        """
        DuckDBë¡œ ì—¬ëŸ¬ íŒŒì¼ì— SQL ì¿¼ë¦¬ ì‹¤í–‰
        
        Args:
            parquet_dir: Parquet íŒŒì¼ ë””ë ‰í† ë¦¬
            start_year: ì‹œì‘ ì—°ë„
            end_year: ì¢…ë£Œ ì—°ë„
            sql_query: SQL ì¿¼ë¦¬ (tick_data í…Œì´ë¸” ì‚¬ìš©)
        
        Returns:
            pandas.DataFrame
        
        Example:
            result = query_period_duckdb(
                'E:/parquet/futures',
                2017, 2019,
                '''
                SELECT ISIN_CODE, COUNT(*) as cnt, AVG(TRD_PRC) as avg_price
                FROM tick_data
                GROUP BY ISIN_CODE
                '''
            )
        """
        import duckdb
        
        # íŒŒì¼ ê²€ìƒ‰
        all_files = list(Path(parquet_dir).glob("*.parquet"))
        period_files = []
        
        for file in all_files:
            period = TickDataConverter.parse_filename_period(file.name)
            if period:
                year, _ = period
                if start_year <= year <= end_year:
                    period_files.append(str(file))
        
        if not period_files:
            raise ValueError(f"{start_year}~{end_year}ë…„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"ì¿¼ë¦¬ ëŒ€ìƒ: {len(period_files)}ê°œ íŒŒì¼")
        
        con = duckdb.connect()
        
        # ì—¬ëŸ¬ íŒŒì¼ì„ í•˜ë‚˜ì˜ í…Œì´ë¸”ë¡œ ì½ê¸°
        files_str = ", ".join(f"'{f}'" for f in period_files)
        query = sql_query.replace('tick_data', f'read_parquet([{files_str}])')
        
        print(f"SQL ì‹¤í–‰ ì¤‘...")
        result = con.execute(query).fetchdf()
        con.close()
        
        print(f"âœ“ ì™„ë£Œ: {len(result):,}ê°œ í–‰ ë°˜í™˜")
        return result


# ============================================================================
# ì‚¬ìš© ì˜ˆì‹œ
# ============================================================================

if __name__ == "__main__":
    
    print("="*80)
    print("ì½”ìŠ¤ì½¤ í‹±ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ v2")
    print("="*80)
    
    # ========================================================================
    # ì˜ˆì‹œ 1: íŠ¹ì • ê¸°ê°„ë§Œ ì „ì²˜ë¦¬
    # ========================================================================
    
    print("\n\n[ì˜ˆì‹œ 1] 2017~2019ë…„ 1ë¶„ê¸°ë§Œ ì „ì²˜ë¦¬")
    print("-"*80)
    
    TickDataConverter.batch_convert(
        input_dir=r"E:\ì„ ë¬¼ ì²´ê²°í‹±ë°ì´í„°(2010.Q1~2023.Q4)",
        output_dir=r"E:\parquet\futures",
        is_derivative=True,
        start_year=2017,
        end_year=2019,
        quarters=[1]  # 1ë¶„ê¸°ë§Œ
    )
    
    # ========================================================================
    # ì˜ˆì‹œ 2: ì—¬ëŸ¬ íŒŒì¼ì„ í•œë²ˆì— ì¿¼ë¦¬ (Polars)
    # ========================================================================
    
    print("\n\n[ì˜ˆì‹œ 2] 2017~2019ë…„ ë°ì´í„° í†µí•© ì¿¼ë¦¬ (Polars)")
    print("-"*80)
    
    try:
        df = MultiFileTickLoader.load_period_polars(
            parquet_dir=r"E:\parquet\futures",
            start_year=2017,
            end_year=2019,
            filters={'ISIN_CODE': 'KR4101M30004'},
            columns=['TRADE_DATE', 'TRD_TM', 'TRD_PRC', 'TRDVOL']
        )
        
        print(f"\në¡œë“œëœ ë°ì´í„°:")
        print(df.head(10))
        print(f"\nì´ {len(df):,}ê°œ í–‰ (ë©”ëª¨ë¦¬ì— ë¡œë“œë¨)")
        
    except Exception as e:
        print(f"Polars ì˜ˆì‹œ ìŠ¤í‚µ: {e}")
    
    # ========================================================================
    # ì˜ˆì‹œ 3: SQL ì§‘ê³„ (DuckDB)
    # ========================================================================
    
    print("\n\n[ì˜ˆì‹œ 3] 2017~2019ë…„ ë°ì´í„° SQL ì§‘ê³„ (DuckDB)")
    print("-"*80)
    
    try:
        result = MultiFileTickLoader.query_period_duckdb(
            parquet_dir=r"E:\parquet\futures",
            start_year=2017,
            end_year=2019,
            sql_query="""
                SELECT 
                    TRADE_DATE,
                    COUNT(*) as trade_count,
                    SUM(TRDVOL) as total_volume,
                    AVG(TRD_PRC) as avg_price
                FROM tick_data
                WHERE ISIN_CODE = 'KR4101M30004'
                GROUP BY TRADE_DATE
                ORDER BY TRADE_DATE
            """
        )
        
        print(f"\nì§‘ê³„ ê²°ê³¼:")
        print(result.head(10))
        
    except Exception as e:
        print(f"DuckDB ì˜ˆì‹œ ìŠ¤í‚µ: {e}")
    
    print("\n\n" + "="*80)
    print("ì™„ë£Œ!")
    print("="*80)
